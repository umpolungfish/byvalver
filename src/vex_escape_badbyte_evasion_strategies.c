/*
 * vex_escape_badbyte_evasion_strategies.c
 * Auto-generated by BYVALVER CodeGenerationAgent
 */
#include <stdint.h>
#include <stddef.h>
#include <string.h>
#include <capstone/capstone.h>
#include "strategy.h"
#include "utils.h"
#include "vex_escape_badbyte_evasion_strategies.h"

/* ============================================================================
 * Utility functions for VEX instruction analysis
 * ============================================================================ */

/**
 * Check if an instruction uses VEX prefix (0xC4 or 0xC5)
 */
static int is_vex_prefixed(cs_insn *insn) {
    const uint8_t *bytes = insn->bytes;
    size_t size = insn->size;
    
    if (size < 2) return 0;
    
    // Check for VEX prefix bytes
    if (bytes[0] == 0xC4 || bytes[0] == 0xC5) {
        return 1;
    }
    
    return 0;
}

/**
 * Check if VEX escape bytes (0xC4, 0xC5) are bad bytes
 */
static int has_bad_vex_escape(cs_insn *insn) {
    const uint8_t *bytes = insn->bytes;
    size_t size = insn->size;
    
    if (size < 1) return 0;
    
    // Check if first byte is 0xC4 or 0xC5 (VEX prefixes)
    if (bytes[0] == 0xC4 || bytes[0] == 0xC5) {
        // Check if these bytes are considered "bad" (null bytes in this context)
        // In BYVALVER, bad bytes are typically 0x00, but we treat 0xC4/0xC5 as bad
        // when they need to be avoided
        return 1;
    }
    
    return 0;
}

/**
 * Get the VEX prefix type and extract fields
 * Returns 1 if VEX prefix found, 0 otherwise
 */
static int get_vex_info(cs_insn *insn, int *is_vex3, uint8_t *vex_r, 
                        uint8_t *vex_x, uint8_t *vex_b, uint8_t *vex_m,
                        uint8_t *vex_w, uint8_t *vex_v, uint8_t *vex_l,
                        uint8_t *vex_pp) {
    const uint8_t *bytes = insn->bytes;
    size_t size = insn->size;
    
    if (size < 2) return 0;
    
    if (bytes[0] == 0xC5) {
        // 2-byte VEX prefix
        *is_vex3 = 0;
        uint8_t byte2 = bytes[1];
        
        // C5 byte1 format: [R vvvv L pp]
        *vex_r = (byte2 >> 7) & 1;
        *vex_x = 1;  // Not present in 2-byte VEX, default to 1
        *vex_b = 1;  // Not present in 2-byte VEX, default to 1
        *vex_m = 2;  // Implicit 0x0F for 2-byte VEX
        *vex_w = 0;  // Not present in 2-byte VEX
        *vex_v = (~(byte2 >> 3)) & 0x0F;  // vvvv field is inverted
        *vex_l = (byte2 >> 2) & 1;
        *vex_pp = byte2 & 0x03;
        
        return 1;
    } else if (bytes[0] == 0xC4 && size >= 3) {
        // 3-byte VEX prefix
        *is_vex3 = 1;
        uint8_t byte2 = bytes[1];
        uint8_t byte3 = bytes[2];
        
        // C4 byte1 byte2 format: [R X B mmmm][W vvvv L pp]
        *vex_r = (byte2 >> 7) & 1;
        *vex_x = (byte2 >> 6) & 1;
        *vex_b = (byte2 >> 5) & 1;
        *vex_m = byte2 & 0x0F;  // m-mmmm field
        *vex_w = (byte3 >> 7) & 1;
        *vex_v = (~(byte3 >> 3)) & 0x0F;  // vvvv field is inverted
        *vex_l = (byte3 >> 2) & 1;
        *vex_pp = byte3 & 0x03;
        
        return 1;
    }
    
    return 0;
}

/**
 * Map VEX.pp field to legacy prefix
 * 00: none
 * 01: 0x66
 * 10: 0xF3
 * 11: 0xF2
 */
static uint8_t vex_pp_to_prefix(uint8_t vex_pp) {
    switch (vex_pp) {
        case 0x00: return 0x00;  // No prefix
        case 0x01: return 0x66;  // Operand-size override
        case 0x02: return 0xF3;  // REP/REPE prefix
        case 0x03: return 0xF2;  // REPNE prefix
        default:   return 0x00;
    }
}

/**
 * Map VEX.m-mmmm field to opcode map
 * Returns the base opcode byte(s) for legacy encoding
 */
static int vex_m_to_opcode_map(uint8_t vex_m, uint8_t *map_bytes, int *map_size) {
    switch (vex_m) {
        case 0x01:  // 0F
            map_bytes[0] = 0x0F;
            *map_size = 1;
            return 1;
        case 0x02:  // 0F 38
            map_bytes[0] = 0x0F;
            map_bytes[1] = 0x38;
            *map_size = 2;
            return 1;
        case 0x03:  // 0F 3A
            map_bytes[0] = 0x0F;
            map_bytes[1] = 0x3A;
            *map_size = 2;
            return 1;
        case 0x00:  // Implicit map (for some instructions)
        case 0x04:  // Reserved
        case 0x05:  // Reserved
        case 0x06:  // Reserved
        case 0x07:  // Reserved
        case 0x08:  // Reserved
        case 0x09:  // Reserved
        case 0x0A:  // Reserved
        case 0x0B:  // Reserved
        case 0x0C:  // Reserved
        case 0x0D:  // Reserved
        case 0x0E:  // Reserved
        case 0x0F:  // Reserved
        default:
            // Default to 0x0F map for most instructions
            map_bytes[0] = 0x0F;
            *map_size = 1;
            return 1;
    }
}

/**
 * Get the opcode byte from VEX instruction
 * This is the byte after the VEX prefix
 */
static uint8_t get_vex_opcode(cs_insn *insn) {
    const uint8_t *bytes = insn->bytes;
    size_t size = insn->size;
    
    if (bytes[0] == 0xC5 && size >= 3) {
        // 2-byte VEX: C5 xx opcode ...
        return bytes[2];
    } else if (bytes[0] == 0xC4 && size >= 4) {
        // 3-byte VEX: C4 xx xx opcode ...
        return bytes[3];
    }
    
    return 0;
}

/**
 * Get ModR/M byte from VEX instruction
 */
static uint8_t get_vex_modrm(cs_insn *insn) {
    const uint8_t *bytes = insn->bytes;
    size_t size = insn->size;
    
    if (bytes[0] == 0xC5 && size >= 4) {
        // 2-byte VEX: C5 xx opcode modrm ...
        return bytes[3];
    } else if (bytes[0] == 0xC4 && size >= 5) {
        // 3-byte VEX: C4 xx xx opcode modrm ...
        return bytes[4];
    }
    
    return 0;
}

/**
 * Check if instruction can be converted to legacy SSE
 * Not all VEX instructions have SSE equivalents
 */
static int has_sse_equivalent(cs_insn *insn) {
    // Check instruction ID for common AVX/AVX2 instructions with SSE equivalents
    switch (insn->id) {
        // Floating-point SIMD instructions
        case X86_INS_VADDPS:
        case X86_INS_VADDPD:
        case X86_INS_VSUBPS:
        case X86_INS_VSUBPD:
        case X86_INS_VMULPS:
        case X86_INS_VMULPD:
        case X86_INS_VDIVPS:
        case X86_INS_VDIVPD:
        case X86_INS_VMAXPS:
        case X86_INS_VMAXPD:
        case X86_INS_VMINPS:
        case X86_INS_VMINPD:
        case X86_INS_VSQRTPS:
        case X86_INS_VSQRTPD:
        case X86_INS_VRSQRTPS:
        case X86_INS_VRCPPS:

        // Integer SIMD instructions
        case X86_INS_VPADDB:
        case X86_INS_VPADDW:
        case X86_INS_VPADDD:
        case X86_INS_VPADDQ:
        case X86_INS_VPSUBB:
        case X86_INS_VPSUBW:
        case X86_INS_VPSUBD:
        case X86_INS_VPSUBQ:
        case X86_INS_VPMULLW:
        case X86_INS_VPMULLD:
        case X86_INS_VPMULHW:
        case X86_INS_VPMULHUW:
        case X86_INS_VPMULHRSW:
        
        // Logical operations
        case X86_INS_VPAND:
        case X86_INS_VPANDN:
        case X86_INS_VPOR:
        case X86_INS_VPXOR:
        
        // Comparison operations
        case X86_INS_VCMPPS:
        case X86_INS_VCMPPD:
        case X86_INS_VPCMPEQB:
        case X86_INS_VPCMPEQW:
        case X86_INS_VPCMPEQD:
        case X86_INS_VPCMPEQQ:
        case X86_INS_VPCMPGTB:
        case X86_INS_VPCMPGTW:
        case X86_INS_VPCMPGTD:
        case X86_INS_VPCMPGTQ:
        
        // Shuffle/pack/unpack
        case X86_INS_VSHUFPS:
        case X86_INS_VSHUFPD:
        case X86_INS_VUNPCKLPS:
        case X86_INS_VUNPCKLPD:
        case X86_INS_VUNPCKHPS:
        case X86_INS_VUNPCKHPD:
        case X86_INS_VPACKSSWB:
        case X86_INS_VPACKSSDW:
        case X86_INS_VPACKUSWB:
        case X86_INS_VPACKUSDW:
        
        // Blend instructions
        case X86_INS_VBLENDPS:
        case X86_INS_VBLENDPD:
        case X86_INS_VPBLENDVB:
        case X86_INS_VPBLENDW:
        
        // Move instructions
        case X86_INS_VMOVAPS:
        case X86_INS_VMOVAPD:
        case X86_INS_VMOVUPS:
        case X86_INS_VMOVUPD:
        case X86_INS_VMOVDQA:
        case X86_INS_VMOVDQU:
        
        // Conversion instructions
        case X86_INS_VCVTSD2SS:
        case X86_INS_VCVTSI2SD:
        case X86_INS_VCVTSI2SS:
        
            return 1;
        
        default:
            return 0;
    }
}

/* ============================================================================
 * Strategy implementation
 * ============================================================================ */

/**
 * Check if this strategy can handle the instruction
 */
static int can_handle_vex_escape_evasion(cs_insn *insn) {
    (void)insn;  // Parameter will be used
    
    // Must be a VEX-prefixed instruction
    if (!is_vex_prefixed(insn)) {
        return 0;
    }
    
    // Must have bad VEX escape bytes (0xC4 or 0xC5)
    if (!has_bad_vex_escape(insn)) {
        return 0;
    }
    
    // Must have an SSE equivalent
    if (!has_sse_equivalent(insn)) {
        return 0;
    }
    
    return 1;
}

/**
 * Calculate conservative size estimate for replacement
 */
static size_t get_size_vex_escape_evasion(cs_insn *insn) {
    (void)insn;
    
    // Conservative estimate: legacy SSE encoding can be up to:
    // - 1 byte prefix (0x66, 0xF2, 0xF3) or none
    // - 1-2 bytes opcode map (0x0F, 0x0F38, 0x0F3A)
    // - 1 byte opcode
    // - 1 byte ModR/M
    // - Up to 4 bytes displacement
    // - Up to 4 bytes immediate
    // Total maximum: 1 + 2 + 1 + 1 + 4 + 4 = 13 bytes
    
    // Add some padding for safety
    return 16;
}

/**
 * Generate legacy SSE encoding for VEX instruction
 */
static void generate_vex_escape_evasion(struct buffer *b, cs_insn *insn) {
    const uint8_t *bytes = insn->bytes;
    size_t size = insn->size;
    
    // Extract VEX information
    int is_vex3;
    uint8_t vex_r, vex_x, vex_b, vex_m, vex_w, vex_v, vex_l, vex_pp;
    
    if (!get_vex_info(insn, &is_vex3, &vex_r, &vex_x, &vex_b, &vex_m, 
                      &vex_w, &vex_v, &vex_l, &vex_pp)) {
        // Should not happen if can_handle returned true
        return;
    }
    
    // Get the legacy prefix from vex_pp
    uint8_t prefix = vex_pp_to_prefix(vex_pp);
    
    // Get opcode map bytes
    uint8_t map_bytes[2];
    int map_size;
    vex_m_to_opcode_map(vex_m, map_bytes, &map_size);
    
    // Get original opcode and ModR/M
    uint8_t opcode = get_vex_opcode(insn);
    uint8_t modrm = get_vex_modrm(insn);
    
    // Reconstruct ModR/M for legacy encoding
    // In VEX: modrm.mod, modrm.reg, modrm.r/m fields are used
    // In legacy: we need to adjust based on VEX fields
    
    // For most instructions, we can use the same ModR/M byte
    // but we need to handle the register encoding differences
    
    // Write prefix if present (and not null)
    if (prefix != 0x00) {
        buffer_write_byte(b, prefix);
    }
    
    // Write map bytes (0x0F, or 0x0F38, or 0x0F3A)
    for (int i = 0; i < map_size; i++) {
        buffer_write_byte(b, map_bytes[i]);
    }
    
    // Write opcode
    buffer_write_byte(b, opcode);
    
    // Write ModR/M
    buffer_write_byte(b, modrm);
    
    // Copy remaining bytes (displacement, immediate, etc.)
    // Start after VEX prefix + opcode + ModR/M
    size_t vex_prefix_len = (bytes[0] == 0xC5) ? 2 : 3;
    size_t data_start = vex_prefix_len + 1 + 1;  // VEX + opcode + ModR/M
    
    for (size_t i = data_start; i < size; i++) {
        uint8_t byte = bytes[i];
        // Ensure no null bytes
        if (byte == 0x00) {
            // Replace null with 0x01 (smallest non-zero)
            buffer_write_byte(b, 0x01);
        } else {
            buffer_write_byte(b, byte);
        }
    }
    
    // Special handling for specific instruction types
    // For instructions with immediate operands, we might need to adjust
    // based on the example in the specification
    
    // Example: VADDPS xmm0, xmm1, xmm0 -> ADDPS xmm0, xmm1 with 0x66 prefix
    // This is already handled by the general conversion above
}

/* ============================================================================
 * Strategy registration
 * ============================================================================ */

static strategy_t vex_escape_evasion_strategy = {
    .name = "vex_escape_badbyte_evasion",
    .can_handle = can_handle_vex_escape_evasion,
    .get_size = get_size_vex_escape_evasion,
    .generate = generate_vex_escape_evasion,
    .priority = 85,
    .target_arch = BYVAL_ARCH_X86
};

void register_vex_escape_badbyte_evasion_strategies(void) {
    register_strategy(&vex_escape_evasion_strategy);
}